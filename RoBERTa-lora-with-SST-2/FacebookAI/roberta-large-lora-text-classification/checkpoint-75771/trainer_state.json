{
  "best_metric": 0.21861857175827026,
  "best_model_checkpoint": "FacebookAI/roberta-large-lora-text-classification/checkpoint-67352",
  "epoch": 9.0,
  "eval_steps": 500,
  "global_step": 75771,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06,
      "grad_norm": 5.361881256103516,
      "learning_rate": 9.940610523815181e-06,
      "loss": 0.6913,
      "step": 500
    },
    {
      "epoch": 0.12,
      "grad_norm": 6.271412372589111,
      "learning_rate": 9.88122104763036e-06,
      "loss": 0.6705,
      "step": 1000
    },
    {
      "epoch": 0.18,
      "grad_norm": 17.509239196777344,
      "learning_rate": 9.821831571445541e-06,
      "loss": 0.3957,
      "step": 1500
    },
    {
      "epoch": 0.24,
      "grad_norm": 38.9614372253418,
      "learning_rate": 9.76244209526072e-06,
      "loss": 0.3653,
      "step": 2000
    },
    {
      "epoch": 0.3,
      "grad_norm": 43.57622528076172,
      "learning_rate": 9.7030526190759e-06,
      "loss": 0.3352,
      "step": 2500
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.1550064086914062,
      "learning_rate": 9.643663142891081e-06,
      "loss": 0.3093,
      "step": 3000
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.6118447780609131,
      "learning_rate": 9.58427366670626e-06,
      "loss": 0.2937,
      "step": 3500
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.2649106979370117,
      "learning_rate": 9.52488419052144e-06,
      "loss": 0.3129,
      "step": 4000
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.16092456877231598,
      "learning_rate": 9.46549471433662e-06,
      "loss": 0.3098,
      "step": 4500
    },
    {
      "epoch": 0.59,
      "grad_norm": 3.2064902782440186,
      "learning_rate": 9.4061052381518e-06,
      "loss": 0.3091,
      "step": 5000
    },
    {
      "epoch": 0.65,
      "grad_norm": 34.7576904296875,
      "learning_rate": 9.346715761966981e-06,
      "loss": 0.2951,
      "step": 5500
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.0253931283950806,
      "learning_rate": 9.28732628578216e-06,
      "loss": 0.286,
      "step": 6000
    },
    {
      "epoch": 0.77,
      "grad_norm": 36.36579132080078,
      "learning_rate": 9.22793680959734e-06,
      "loss": 0.2679,
      "step": 6500
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.8325618505477905,
      "learning_rate": 9.16854733341252e-06,
      "loss": 0.2888,
      "step": 7000
    },
    {
      "epoch": 0.89,
      "grad_norm": 14.45110034942627,
      "learning_rate": 9.1091578572277e-06,
      "loss": 0.269,
      "step": 7500
    },
    {
      "epoch": 0.95,
      "grad_norm": 54.04213333129883,
      "learning_rate": 9.04976838104288e-06,
      "loss": 0.2554,
      "step": 8000
    },
    {
      "epoch": 1.0,
      "eval_accuracy": {
        "accuracy": 0.9461009174311926
      },
      "eval_loss": 0.2717190086841583,
      "eval_runtime": 4.4395,
      "eval_samples_per_second": 196.418,
      "eval_steps_per_second": 24.552,
      "step": 8419
    },
    {
      "epoch": 1.01,
      "grad_norm": 15.572806358337402,
      "learning_rate": 8.99037890485806e-06,
      "loss": 0.2818,
      "step": 8500
    },
    {
      "epoch": 1.07,
      "grad_norm": 23.930089950561523,
      "learning_rate": 8.93098942867324e-06,
      "loss": 0.2903,
      "step": 9000
    },
    {
      "epoch": 1.13,
      "grad_norm": 0.32483187317848206,
      "learning_rate": 8.87159995248842e-06,
      "loss": 0.2677,
      "step": 9500
    },
    {
      "epoch": 1.19,
      "grad_norm": 13.08991527557373,
      "learning_rate": 8.8122104763036e-06,
      "loss": 0.2762,
      "step": 10000
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.1624449491500854,
      "learning_rate": 8.752821000118779e-06,
      "loss": 0.2739,
      "step": 10500
    },
    {
      "epoch": 1.31,
      "grad_norm": 1.2562707662582397,
      "learning_rate": 8.69343152393396e-06,
      "loss": 0.2596,
      "step": 11000
    },
    {
      "epoch": 1.37,
      "grad_norm": 1.534806728363037,
      "learning_rate": 8.63404204774914e-06,
      "loss": 0.2678,
      "step": 11500
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.5321853756904602,
      "learning_rate": 8.574652571564319e-06,
      "loss": 0.254,
      "step": 12000
    },
    {
      "epoch": 1.48,
      "grad_norm": 9.650918006896973,
      "learning_rate": 8.5152630953795e-06,
      "loss": 0.2481,
      "step": 12500
    },
    {
      "epoch": 1.54,
      "grad_norm": 46.82233428955078,
      "learning_rate": 8.455873619194679e-06,
      "loss": 0.2776,
      "step": 13000
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.9415331482887268,
      "learning_rate": 8.39648414300986e-06,
      "loss": 0.2615,
      "step": 13500
    },
    {
      "epoch": 1.66,
      "grad_norm": 0.7222713828086853,
      "learning_rate": 8.33709466682504e-06,
      "loss": 0.2674,
      "step": 14000
    },
    {
      "epoch": 1.72,
      "grad_norm": 3.2882790565490723,
      "learning_rate": 8.277705190640219e-06,
      "loss": 0.2347,
      "step": 14500
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.13518117368221283,
      "learning_rate": 8.2183157144554e-06,
      "loss": 0.2524,
      "step": 15000
    },
    {
      "epoch": 1.84,
      "grad_norm": 41.654945373535156,
      "learning_rate": 8.158926238270578e-06,
      "loss": 0.2608,
      "step": 15500
    },
    {
      "epoch": 1.9,
      "grad_norm": 1.8292756080627441,
      "learning_rate": 8.099536762085759e-06,
      "loss": 0.2606,
      "step": 16000
    },
    {
      "epoch": 1.96,
      "grad_norm": 60.59553527832031,
      "learning_rate": 8.04014728590094e-06,
      "loss": 0.255,
      "step": 16500
    },
    {
      "epoch": 2.0,
      "eval_accuracy": {
        "accuracy": 0.9472477064220184
      },
      "eval_loss": 0.24462157487869263,
      "eval_runtime": 4.3952,
      "eval_samples_per_second": 198.4,
      "eval_steps_per_second": 24.8,
      "step": 16838
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.0977386012673378,
      "learning_rate": 7.980757809716119e-06,
      "loss": 0.254,
      "step": 17000
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.12465274333953857,
      "learning_rate": 7.9213683335313e-06,
      "loss": 0.2415,
      "step": 17500
    },
    {
      "epoch": 2.14,
      "grad_norm": 0.31149986386299133,
      "learning_rate": 7.861978857346478e-06,
      "loss": 0.2309,
      "step": 18000
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.3325464725494385,
      "learning_rate": 7.802589381161659e-06,
      "loss": 0.2527,
      "step": 18500
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.10582500696182251,
      "learning_rate": 7.74319990497684e-06,
      "loss": 0.2405,
      "step": 19000
    },
    {
      "epoch": 2.32,
      "grad_norm": 17.23822784423828,
      "learning_rate": 7.683810428792018e-06,
      "loss": 0.2345,
      "step": 19500
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.16444504261016846,
      "learning_rate": 7.624420952607199e-06,
      "loss": 0.2542,
      "step": 20000
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.10750920325517654,
      "learning_rate": 7.565031476422379e-06,
      "loss": 0.2663,
      "step": 20500
    },
    {
      "epoch": 2.49,
      "grad_norm": 45.074066162109375,
      "learning_rate": 7.5056420002375585e-06,
      "loss": 0.2465,
      "step": 21000
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.21294569969177246,
      "learning_rate": 7.446252524052738e-06,
      "loss": 0.2391,
      "step": 21500
    },
    {
      "epoch": 2.61,
      "grad_norm": 0.11760929226875305,
      "learning_rate": 7.386863047867918e-06,
      "loss": 0.2407,
      "step": 22000
    },
    {
      "epoch": 2.67,
      "grad_norm": 0.9156174063682556,
      "learning_rate": 7.327473571683098e-06,
      "loss": 0.2537,
      "step": 22500
    },
    {
      "epoch": 2.73,
      "grad_norm": 15.503697395324707,
      "learning_rate": 7.268084095498278e-06,
      "loss": 0.2288,
      "step": 23000
    },
    {
      "epoch": 2.79,
      "grad_norm": 0.3014817237854004,
      "learning_rate": 7.2086946193134574e-06,
      "loss": 0.2383,
      "step": 23500
    },
    {
      "epoch": 2.85,
      "grad_norm": 18.046743392944336,
      "learning_rate": 7.149305143128639e-06,
      "loss": 0.215,
      "step": 24000
    },
    {
      "epoch": 2.91,
      "grad_norm": 0.20034627616405487,
      "learning_rate": 7.089915666943819e-06,
      "loss": 0.2674,
      "step": 24500
    },
    {
      "epoch": 2.97,
      "grad_norm": 0.17034536600112915,
      "learning_rate": 7.0305261907589985e-06,
      "loss": 0.231,
      "step": 25000
    },
    {
      "epoch": 3.0,
      "eval_accuracy": {
        "accuracy": 0.9506880733944955
      },
      "eval_loss": 0.22862671315670013,
      "eval_runtime": 4.3488,
      "eval_samples_per_second": 200.513,
      "eval_steps_per_second": 25.064,
      "step": 25257
    },
    {
      "epoch": 3.03,
      "grad_norm": 0.2721640169620514,
      "learning_rate": 6.971136714574178e-06,
      "loss": 0.2396,
      "step": 25500
    },
    {
      "epoch": 3.09,
      "grad_norm": 12.581338882446289,
      "learning_rate": 6.911747238389358e-06,
      "loss": 0.1986,
      "step": 26000
    },
    {
      "epoch": 3.15,
      "grad_norm": 0.12712033092975616,
      "learning_rate": 6.852357762204538e-06,
      "loss": 0.2222,
      "step": 26500
    },
    {
      "epoch": 3.21,
      "grad_norm": 0.22755827009677887,
      "learning_rate": 6.792968286019718e-06,
      "loss": 0.2232,
      "step": 27000
    },
    {
      "epoch": 3.27,
      "grad_norm": 6.669631004333496,
      "learning_rate": 6.733578809834897e-06,
      "loss": 0.2357,
      "step": 27500
    },
    {
      "epoch": 3.33,
      "grad_norm": 0.16313442587852478,
      "learning_rate": 6.674189333650077e-06,
      "loss": 0.2362,
      "step": 28000
    },
    {
      "epoch": 3.39,
      "grad_norm": 0.2532236576080322,
      "learning_rate": 6.614799857465257e-06,
      "loss": 0.247,
      "step": 28500
    },
    {
      "epoch": 3.44,
      "grad_norm": 0.17328377068042755,
      "learning_rate": 6.5554103812804384e-06,
      "loss": 0.2179,
      "step": 29000
    },
    {
      "epoch": 3.5,
      "grad_norm": 19.85027503967285,
      "learning_rate": 6.496020905095618e-06,
      "loss": 0.2408,
      "step": 29500
    },
    {
      "epoch": 3.56,
      "grad_norm": 0.8970791697502136,
      "learning_rate": 6.436631428910798e-06,
      "loss": 0.2427,
      "step": 30000
    },
    {
      "epoch": 3.62,
      "grad_norm": 24.764772415161133,
      "learning_rate": 6.377241952725978e-06,
      "loss": 0.2374,
      "step": 30500
    },
    {
      "epoch": 3.68,
      "grad_norm": 77.06089782714844,
      "learning_rate": 6.317852476541158e-06,
      "loss": 0.2276,
      "step": 31000
    },
    {
      "epoch": 3.74,
      "grad_norm": 23.89969253540039,
      "learning_rate": 6.258463000356337e-06,
      "loss": 0.2238,
      "step": 31500
    },
    {
      "epoch": 3.8,
      "grad_norm": 7.493217945098877,
      "learning_rate": 6.199073524171517e-06,
      "loss": 0.216,
      "step": 32000
    },
    {
      "epoch": 3.86,
      "grad_norm": 93.95704650878906,
      "learning_rate": 6.139684047986697e-06,
      "loss": 0.2264,
      "step": 32500
    },
    {
      "epoch": 3.92,
      "grad_norm": 0.27931976318359375,
      "learning_rate": 6.080294571801877e-06,
      "loss": 0.239,
      "step": 33000
    },
    {
      "epoch": 3.98,
      "grad_norm": 0.04023019224405289,
      "learning_rate": 6.0209050956170565e-06,
      "loss": 0.224,
      "step": 33500
    },
    {
      "epoch": 4.0,
      "eval_accuracy": {
        "accuracy": 0.9552752293577982
      },
      "eval_loss": 0.24052530527114868,
      "eval_runtime": 4.3414,
      "eval_samples_per_second": 200.858,
      "eval_steps_per_second": 25.107,
      "step": 33676
    },
    {
      "epoch": 4.04,
      "grad_norm": 36.01657485961914,
      "learning_rate": 5.961515619432236e-06,
      "loss": 0.2338,
      "step": 34000
    },
    {
      "epoch": 4.1,
      "grad_norm": 94.50857543945312,
      "learning_rate": 5.902126143247418e-06,
      "loss": 0.2135,
      "step": 34500
    },
    {
      "epoch": 4.16,
      "grad_norm": 18.08196449279785,
      "learning_rate": 5.8427366670625975e-06,
      "loss": 0.2345,
      "step": 35000
    },
    {
      "epoch": 4.22,
      "grad_norm": 0.409799188375473,
      "learning_rate": 5.783347190877777e-06,
      "loss": 0.2202,
      "step": 35500
    },
    {
      "epoch": 4.28,
      "grad_norm": 0.3508431315422058,
      "learning_rate": 5.723957714692957e-06,
      "loss": 0.2172,
      "step": 36000
    },
    {
      "epoch": 4.34,
      "grad_norm": 102.82508850097656,
      "learning_rate": 5.664568238508137e-06,
      "loss": 0.2232,
      "step": 36500
    },
    {
      "epoch": 4.39,
      "grad_norm": 0.5636502504348755,
      "learning_rate": 5.605178762323317e-06,
      "loss": 0.213,
      "step": 37000
    },
    {
      "epoch": 4.45,
      "grad_norm": 120.53170776367188,
      "learning_rate": 5.5457892861384965e-06,
      "loss": 0.2248,
      "step": 37500
    },
    {
      "epoch": 4.51,
      "grad_norm": 0.02982567623257637,
      "learning_rate": 5.486399809953676e-06,
      "loss": 0.2164,
      "step": 38000
    },
    {
      "epoch": 4.57,
      "grad_norm": 0.13873542845249176,
      "learning_rate": 5.427010333768856e-06,
      "loss": 0.2081,
      "step": 38500
    },
    {
      "epoch": 4.63,
      "grad_norm": 0.2085520178079605,
      "learning_rate": 5.367620857584036e-06,
      "loss": 0.2217,
      "step": 39000
    },
    {
      "epoch": 4.69,
      "grad_norm": 35.56204605102539,
      "learning_rate": 5.308231381399217e-06,
      "loss": 0.2058,
      "step": 39500
    },
    {
      "epoch": 4.75,
      "grad_norm": 37.18217086791992,
      "learning_rate": 5.248841905214397e-06,
      "loss": 0.2258,
      "step": 40000
    },
    {
      "epoch": 4.81,
      "grad_norm": 225.20506286621094,
      "learning_rate": 5.189452429029577e-06,
      "loss": 0.2205,
      "step": 40500
    },
    {
      "epoch": 4.87,
      "grad_norm": 15.017632484436035,
      "learning_rate": 5.130062952844757e-06,
      "loss": 0.2278,
      "step": 41000
    },
    {
      "epoch": 4.93,
      "grad_norm": 0.1395639181137085,
      "learning_rate": 5.0706734766599364e-06,
      "loss": 0.2368,
      "step": 41500
    },
    {
      "epoch": 4.99,
      "grad_norm": 73.51671600341797,
      "learning_rate": 5.011284000475116e-06,
      "loss": 0.2225,
      "step": 42000
    },
    {
      "epoch": 5.0,
      "eval_accuracy": {
        "accuracy": 0.9529816513761468
      },
      "eval_loss": 0.25045618414878845,
      "eval_runtime": 4.3408,
      "eval_samples_per_second": 200.885,
      "eval_steps_per_second": 25.111,
      "step": 42095
    },
    {
      "epoch": 5.05,
      "grad_norm": 0.06898052990436554,
      "learning_rate": 4.951894524290296e-06,
      "loss": 0.2038,
      "step": 42500
    },
    {
      "epoch": 5.11,
      "grad_norm": 0.09485454857349396,
      "learning_rate": 4.892505048105476e-06,
      "loss": 0.2177,
      "step": 43000
    },
    {
      "epoch": 5.17,
      "grad_norm": 0.8969497680664062,
      "learning_rate": 4.833115571920656e-06,
      "loss": 0.2094,
      "step": 43500
    },
    {
      "epoch": 5.23,
      "grad_norm": 0.15269917249679565,
      "learning_rate": 4.773726095735836e-06,
      "loss": 0.2312,
      "step": 44000
    },
    {
      "epoch": 5.29,
      "grad_norm": 70.94088745117188,
      "learning_rate": 4.714336619551016e-06,
      "loss": 0.2074,
      "step": 44500
    },
    {
      "epoch": 5.35,
      "grad_norm": 0.18066546320915222,
      "learning_rate": 4.654947143366196e-06,
      "loss": 0.2237,
      "step": 45000
    },
    {
      "epoch": 5.4,
      "grad_norm": 18.540870666503906,
      "learning_rate": 4.5955576671813755e-06,
      "loss": 0.2221,
      "step": 45500
    },
    {
      "epoch": 5.46,
      "grad_norm": 126.34268951416016,
      "learning_rate": 4.536168190996556e-06,
      "loss": 0.2173,
      "step": 46000
    },
    {
      "epoch": 5.52,
      "grad_norm": 26.26166343688965,
      "learning_rate": 4.476778714811736e-06,
      "loss": 0.2231,
      "step": 46500
    },
    {
      "epoch": 5.58,
      "grad_norm": 23.838499069213867,
      "learning_rate": 4.417389238626916e-06,
      "loss": 0.2232,
      "step": 47000
    },
    {
      "epoch": 5.64,
      "grad_norm": 0.7099558115005493,
      "learning_rate": 4.3579997624420955e-06,
      "loss": 0.2158,
      "step": 47500
    },
    {
      "epoch": 5.7,
      "grad_norm": 0.07194209843873978,
      "learning_rate": 4.298610286257275e-06,
      "loss": 0.2074,
      "step": 48000
    },
    {
      "epoch": 5.76,
      "grad_norm": 0.9443879723548889,
      "learning_rate": 4.239220810072456e-06,
      "loss": 0.2027,
      "step": 48500
    },
    {
      "epoch": 5.82,
      "grad_norm": 0.04170237109065056,
      "learning_rate": 4.179831333887636e-06,
      "loss": 0.1952,
      "step": 49000
    },
    {
      "epoch": 5.88,
      "grad_norm": 0.4255501925945282,
      "learning_rate": 4.1204418577028155e-06,
      "loss": 0.227,
      "step": 49500
    },
    {
      "epoch": 5.94,
      "grad_norm": 24.47369956970215,
      "learning_rate": 4.061052381517995e-06,
      "loss": 0.2227,
      "step": 50000
    },
    {
      "epoch": 6.0,
      "grad_norm": 41.29465103149414,
      "learning_rate": 4.001662905333175e-06,
      "loss": 0.2097,
      "step": 50500
    },
    {
      "epoch": 6.0,
      "eval_accuracy": {
        "accuracy": 0.9529816513761468
      },
      "eval_loss": 0.2519471049308777,
      "eval_runtime": 4.3448,
      "eval_samples_per_second": 200.7,
      "eval_steps_per_second": 25.087,
      "step": 50514
    },
    {
      "epoch": 6.06,
      "grad_norm": 0.20459294319152832,
      "learning_rate": 3.942273429148355e-06,
      "loss": 0.2239,
      "step": 51000
    },
    {
      "epoch": 6.12,
      "grad_norm": 56.10619354248047,
      "learning_rate": 3.8828839529635355e-06,
      "loss": 0.2064,
      "step": 51500
    },
    {
      "epoch": 6.18,
      "grad_norm": 0.7328051924705505,
      "learning_rate": 3.823494476778715e-06,
      "loss": 0.2017,
      "step": 52000
    },
    {
      "epoch": 6.24,
      "grad_norm": 26.66927146911621,
      "learning_rate": 3.764105000593895e-06,
      "loss": 0.2019,
      "step": 52500
    },
    {
      "epoch": 6.3,
      "grad_norm": 36.51388931274414,
      "learning_rate": 3.704715524409075e-06,
      "loss": 0.2175,
      "step": 53000
    },
    {
      "epoch": 6.35,
      "grad_norm": 0.14889688789844513,
      "learning_rate": 3.6453260482242546e-06,
      "loss": 0.1893,
      "step": 53500
    },
    {
      "epoch": 6.41,
      "grad_norm": 82.78987884521484,
      "learning_rate": 3.5859365720394353e-06,
      "loss": 0.2206,
      "step": 54000
    },
    {
      "epoch": 6.47,
      "grad_norm": 0.38310274481773376,
      "learning_rate": 3.526547095854615e-06,
      "loss": 0.199,
      "step": 54500
    },
    {
      "epoch": 6.53,
      "grad_norm": 0.12193440645933151,
      "learning_rate": 3.467157619669795e-06,
      "loss": 0.1655,
      "step": 55000
    },
    {
      "epoch": 6.59,
      "grad_norm": 2.1044692993164062,
      "learning_rate": 3.4077681434849746e-06,
      "loss": 0.2213,
      "step": 55500
    },
    {
      "epoch": 6.65,
      "grad_norm": 0.15258686244487762,
      "learning_rate": 3.3483786673001544e-06,
      "loss": 0.1976,
      "step": 56000
    },
    {
      "epoch": 6.71,
      "grad_norm": 0.5553988814353943,
      "learning_rate": 3.288989191115335e-06,
      "loss": 0.2187,
      "step": 56500
    },
    {
      "epoch": 6.77,
      "grad_norm": 0.1137290820479393,
      "learning_rate": 3.229599714930515e-06,
      "loss": 0.2056,
      "step": 57000
    },
    {
      "epoch": 6.83,
      "grad_norm": 0.09350970387458801,
      "learning_rate": 3.1702102387456946e-06,
      "loss": 0.22,
      "step": 57500
    },
    {
      "epoch": 6.89,
      "grad_norm": 0.1815962940454483,
      "learning_rate": 3.1108207625608744e-06,
      "loss": 0.2106,
      "step": 58000
    },
    {
      "epoch": 6.95,
      "grad_norm": 0.47056278586387634,
      "learning_rate": 3.051431286376054e-06,
      "loss": 0.2081,
      "step": 58500
    },
    {
      "epoch": 7.0,
      "eval_accuracy": {
        "accuracy": 0.9575688073394495
      },
      "eval_loss": 0.23053409159183502,
      "eval_runtime": 4.3418,
      "eval_samples_per_second": 200.84,
      "eval_steps_per_second": 25.105,
      "step": 58933
    },
    {
      "epoch": 7.01,
      "grad_norm": 0.33947351574897766,
      "learning_rate": 2.9920418101912348e-06,
      "loss": 0.21,
      "step": 59000
    },
    {
      "epoch": 7.07,
      "grad_norm": 0.27297213673591614,
      "learning_rate": 2.9326523340064146e-06,
      "loss": 0.2189,
      "step": 59500
    },
    {
      "epoch": 7.13,
      "grad_norm": 23.239641189575195,
      "learning_rate": 2.8732628578215944e-06,
      "loss": 0.2065,
      "step": 60000
    },
    {
      "epoch": 7.19,
      "grad_norm": 0.19807173311710358,
      "learning_rate": 2.813873381636774e-06,
      "loss": 0.2174,
      "step": 60500
    },
    {
      "epoch": 7.25,
      "grad_norm": 0.20976775884628296,
      "learning_rate": 2.754483905451954e-06,
      "loss": 0.2031,
      "step": 61000
    },
    {
      "epoch": 7.3,
      "grad_norm": 0.07393764704465866,
      "learning_rate": 2.6950944292671337e-06,
      "loss": 0.2113,
      "step": 61500
    },
    {
      "epoch": 7.36,
      "grad_norm": 106.45829010009766,
      "learning_rate": 2.6357049530823143e-06,
      "loss": 0.2002,
      "step": 62000
    },
    {
      "epoch": 7.42,
      "grad_norm": 20.347698211669922,
      "learning_rate": 2.576315476897494e-06,
      "loss": 0.1937,
      "step": 62500
    },
    {
      "epoch": 7.48,
      "grad_norm": 0.09500273317098618,
      "learning_rate": 2.516926000712674e-06,
      "loss": 0.1882,
      "step": 63000
    },
    {
      "epoch": 7.54,
      "grad_norm": 38.396305084228516,
      "learning_rate": 2.4575365245278537e-06,
      "loss": 0.1932,
      "step": 63500
    },
    {
      "epoch": 7.6,
      "grad_norm": 0.31282320618629456,
      "learning_rate": 2.398147048343034e-06,
      "loss": 0.2002,
      "step": 64000
    },
    {
      "epoch": 7.66,
      "grad_norm": 4.183929443359375,
      "learning_rate": 2.3387575721582137e-06,
      "loss": 0.1903,
      "step": 64500
    },
    {
      "epoch": 7.72,
      "grad_norm": 110.33601379394531,
      "learning_rate": 2.279368095973394e-06,
      "loss": 0.2276,
      "step": 65000
    },
    {
      "epoch": 7.78,
      "grad_norm": 0.6022929549217224,
      "learning_rate": 2.2199786197885737e-06,
      "loss": 0.2162,
      "step": 65500
    },
    {
      "epoch": 7.84,
      "grad_norm": 0.22992858290672302,
      "learning_rate": 2.1605891436037535e-06,
      "loss": 0.1756,
      "step": 66000
    },
    {
      "epoch": 7.9,
      "grad_norm": 275.1463623046875,
      "learning_rate": 2.1011996674189337e-06,
      "loss": 0.2209,
      "step": 66500
    },
    {
      "epoch": 7.96,
      "grad_norm": 0.05812607705593109,
      "learning_rate": 2.0418101912341134e-06,
      "loss": 0.2028,
      "step": 67000
    },
    {
      "epoch": 8.0,
      "eval_accuracy": {
        "accuracy": 0.9598623853211009
      },
      "eval_loss": 0.21861857175827026,
      "eval_runtime": 4.3405,
      "eval_samples_per_second": 200.897,
      "eval_steps_per_second": 25.112,
      "step": 67352
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.045285020023584366,
      "learning_rate": 1.9824207150492937e-06,
      "loss": 0.2297,
      "step": 67500
    },
    {
      "epoch": 8.08,
      "grad_norm": 0.17943057417869568,
      "learning_rate": 1.9230312388644734e-06,
      "loss": 0.2194,
      "step": 68000
    },
    {
      "epoch": 8.14,
      "grad_norm": 0.3934827446937561,
      "learning_rate": 1.8636417626796532e-06,
      "loss": 0.2176,
      "step": 68500
    },
    {
      "epoch": 8.2,
      "grad_norm": 33.506591796875,
      "learning_rate": 1.8042522864948334e-06,
      "loss": 0.2061,
      "step": 69000
    },
    {
      "epoch": 8.26,
      "grad_norm": 0.17072613537311554,
      "learning_rate": 1.7448628103100132e-06,
      "loss": 0.1924,
      "step": 69500
    },
    {
      "epoch": 8.31,
      "grad_norm": 0.10775291919708252,
      "learning_rate": 1.685473334125193e-06,
      "loss": 0.2122,
      "step": 70000
    },
    {
      "epoch": 8.37,
      "grad_norm": 0.42415812611579895,
      "learning_rate": 1.6260838579403732e-06,
      "loss": 0.2206,
      "step": 70500
    },
    {
      "epoch": 8.43,
      "grad_norm": 0.30653896927833557,
      "learning_rate": 1.566694381755553e-06,
      "loss": 0.1934,
      "step": 71000
    },
    {
      "epoch": 8.49,
      "grad_norm": 0.11517713963985443,
      "learning_rate": 1.5073049055707332e-06,
      "loss": 0.2133,
      "step": 71500
    },
    {
      "epoch": 8.55,
      "grad_norm": 0.8617263436317444,
      "learning_rate": 1.447915429385913e-06,
      "loss": 0.1717,
      "step": 72000
    },
    {
      "epoch": 8.61,
      "grad_norm": 22.29974365234375,
      "learning_rate": 1.3885259532010928e-06,
      "loss": 0.2251,
      "step": 72500
    },
    {
      "epoch": 8.67,
      "grad_norm": 0.1818522810935974,
      "learning_rate": 1.329136477016273e-06,
      "loss": 0.2111,
      "step": 73000
    },
    {
      "epoch": 8.73,
      "grad_norm": 0.2631188631057739,
      "learning_rate": 1.2697470008314528e-06,
      "loss": 0.1857,
      "step": 73500
    },
    {
      "epoch": 8.79,
      "grad_norm": 0.15248100459575653,
      "learning_rate": 1.2103575246466327e-06,
      "loss": 0.1969,
      "step": 74000
    },
    {
      "epoch": 8.85,
      "grad_norm": 6.019566535949707,
      "learning_rate": 1.1509680484618127e-06,
      "loss": 0.2039,
      "step": 74500
    },
    {
      "epoch": 8.91,
      "grad_norm": 82.33521270751953,
      "learning_rate": 1.0915785722769925e-06,
      "loss": 0.2047,
      "step": 75000
    },
    {
      "epoch": 8.97,
      "grad_norm": 0.6072283387184143,
      "learning_rate": 1.0321890960921725e-06,
      "loss": 0.1937,
      "step": 75500
    },
    {
      "epoch": 9.0,
      "eval_accuracy": {
        "accuracy": 0.9610091743119266
      },
      "eval_loss": 0.22924000024795532,
      "eval_runtime": 4.347,
      "eval_samples_per_second": 200.596,
      "eval_steps_per_second": 25.075,
      "step": 75771
    }
  ],
  "logging_steps": 500,
  "max_steps": 84190,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "total_flos": 3.367150656435533e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
