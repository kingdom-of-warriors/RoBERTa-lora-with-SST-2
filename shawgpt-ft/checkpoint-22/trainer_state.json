{
  "best_metric": 2.001673698425293,
  "best_model_checkpoint": "shawgpt-ft/checkpoint-22",
  "epoch": 6.769230769230769,
  "eval_steps": 500,
  "global_step": 22,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.92,
      "grad_norm": 2.1001765727996826,
      "learning_rate": 0.00019285714285714286,
      "loss": 4.593,
      "step": 3
    },
    {
      "epoch": 0.92,
      "eval_loss": 3.9607839584350586,
      "eval_runtime": 4.3176,
      "eval_samples_per_second": 2.084,
      "eval_steps_per_second": 0.695,
      "step": 3
    },
    {
      "epoch": 1.85,
      "grad_norm": 2.246812582015991,
      "learning_rate": 0.00017142857142857143,
      "loss": 4.043,
      "step": 6
    },
    {
      "epoch": 1.85,
      "eval_loss": 3.4345009326934814,
      "eval_runtime": 4.3193,
      "eval_samples_per_second": 2.084,
      "eval_steps_per_second": 0.695,
      "step": 6
    },
    {
      "epoch": 2.77,
      "grad_norm": 2.4365179538726807,
      "learning_rate": 0.00015000000000000001,
      "loss": 3.4712,
      "step": 9
    },
    {
      "epoch": 2.77,
      "eval_loss": 2.989267587661743,
      "eval_runtime": 4.3232,
      "eval_samples_per_second": 2.082,
      "eval_steps_per_second": 0.694,
      "step": 9
    },
    {
      "epoch": 4.0,
      "grad_norm": 2.2313551902770996,
      "learning_rate": 0.00012142857142857143,
      "loss": 2.2692,
      "step": 13
    },
    {
      "epoch": 4.0,
      "eval_loss": 2.5745439529418945,
      "eval_runtime": 4.3234,
      "eval_samples_per_second": 2.082,
      "eval_steps_per_second": 0.694,
      "step": 13
    },
    {
      "epoch": 4.92,
      "grad_norm": 4.361978054046631,
      "learning_rate": 0.0001,
      "loss": 2.6944,
      "step": 16
    },
    {
      "epoch": 4.92,
      "eval_loss": 2.3169949054718018,
      "eval_runtime": 4.3245,
      "eval_samples_per_second": 2.081,
      "eval_steps_per_second": 0.694,
      "step": 16
    },
    {
      "epoch": 5.85,
      "grad_norm": 4.994891166687012,
      "learning_rate": 7.857142857142858e-05,
      "loss": 2.3585,
      "step": 19
    },
    {
      "epoch": 5.85,
      "eval_loss": 2.131978750228882,
      "eval_runtime": 4.3226,
      "eval_samples_per_second": 2.082,
      "eval_steps_per_second": 0.694,
      "step": 19
    },
    {
      "epoch": 6.77,
      "grad_norm": 5.442285060882568,
      "learning_rate": 5.714285714285714e-05,
      "loss": 2.1608,
      "step": 22
    },
    {
      "epoch": 6.77,
      "eval_loss": 2.001673698425293,
      "eval_runtime": 4.321,
      "eval_samples_per_second": 2.083,
      "eval_steps_per_second": 0.694,
      "step": 22
    }
  ],
  "logging_steps": 500,
  "max_steps": 30,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "total_flos": 75108647190528.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
