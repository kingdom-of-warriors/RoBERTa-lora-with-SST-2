## 一、项目介绍

这个项目是用来熟悉Lora微调大模型的，里面给出了用Lora微调RoBERTa（BERT的变种）的代码例子，它微调出了一个可以分辨句子是褒义还是贬义的下游模型。

## 二、环境配置

在base环境中，运行以下指令
```shell
bash set_up.sh
```

 并输入你想创建的环境名字，即可自动安装所需要的库。

## 三、算力需求

我一直想找一个用我的电脑可以跑的Lora微调代码，这个是我在youtube上找到的代码和视频，原代码[链接](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/fine-tuning)，原视频[链接](https://www.youtube.com/watch?v=eC6Hd1hFvos)，不过我对其进行了改进，使用了更好的RoBERTa骨架和更标准的little-SST-2数据集，让微调准确率达到了96.1%。后续可能还会加入数据清洗的模块。

想跑通这个代码，我想只要电脑有独显就可以，我的4060跑它只需要十几分钟，显存要求大约为3G，所以这是一个比较适合普通人了解Lora的项目。

## 四、数据集介绍

我使用的是不完整的SST-2模型，原模型有67k条训练数据和1.7k条测试数据，这里我只使用了7.3k条训练数据（是6.7k条训练数据与0.6k条开发数据的合并），这样训练时间可以大大减少，而且效果也差不多。下面引用一篇博客对SST-2的描述：

SST-2(The Stanford Sentiment Treebank，斯坦福情感树库)，单句子分类任务，包含电影评论中的句子和它们情感的人类注释。这项任务是给定句子的情感，类别分为两类正面情感（positive，样本标签对应为1）和负面情感（negative，样本标签对应为0），并且只用句子级别的标签。也就是，本任务也是一个二分类任务，针对句子级别，分为正面和负面情感。

样本个数：训练集67, 350个，开发集873个，测试集1, 821个。
任务：情感分类，正面情感和负面情感二分类。
评价准则：accuracy。
注意到，由于句子来源于电影评论，又有它们情感的人类注释，不同于CoLA的整体偏短，有些句子很长，有些句子很短，长短并不整齐划一。

原文链接：https://blog.csdn.net/qq_33583069/article/details/115734097

## 五、评估模型

想要评估模型，可见ipynb的第四部分。
